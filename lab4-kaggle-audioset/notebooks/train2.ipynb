{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torchaudio.transforms as T\n",
    "from scipy import stats as st\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "from torchmetrics.classification import (\n",
    "    Accuracy,\n",
    "    F1Score,\n",
    "    MultilabelAccuracy,\n",
    "    MultilabelF1Score,\n",
    ")\n",
    "from torchvision.models import resnet34\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from transformers import ASTConfig, AutoFeatureExtractor, ASTForAudioClassification\n",
    "\n",
    "\n",
    "from src.utils.train_val_split import train_val_split\n",
    "from train_val_functions import train_epoch, validate\n",
    "tqdm.pandas()\n",
    "\n",
    "SEED=12345\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "SAMPLE_RATE = 16000\n",
    "DATA_PATH = Path(\"data/raw/\")\n",
    "\n",
    "train_csv_path = DATA_PATH / \"train.csv\"\n",
    "train_audio_path = DATA_PATH / \"audio_train\"\n",
    "\n",
    "test_csv_path = DATA_PATH / \"test.csv\"\n",
    "test_audio_path = DATA_PATH /  \"audio_test\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(train_csv_path)\n",
    "CLASSES_NAMES = sorted(train_csv['label'].unique())\n",
    "\n",
    "train_csv, val_csv = train_val_split(train_audio_path, train_csv, val_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Acoustic_guitar', 'Applause', 'Bark', 'Bass_drum', 'Burping_or_eructation', 'Bus', 'Cello', 'Chime', 'Clarinet', 'Computer_keyboard', 'Cough', 'Cowbell', 'Double_bass', 'Drawer_open_or_close', 'Electric_piano', 'Fart', 'Finger_snapping', 'Fireworks', 'Flute', 'Glockenspiel', 'Gong', 'Gunshot_or_gunfire', 'Harmonica', 'Hi-hat', 'Keys_jangling', 'Knock', 'Laughter', 'Meow', 'Microwave_oven', 'Oboe', 'Saxophone', 'Scissors', 'Shatter', 'Snare_drum', 'Squeak', 'Tambourine', 'Tearing', 'Telephone', 'Trumpet', 'Violin_or_fiddle', 'Writing', "
     ]
    }
   ],
   "source": [
    "for i in sorted(train_csv['label'].unique()):\n",
    "    print(f\"'{i}',\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5131.000000</td>\n",
       "      <td>552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.805609</td>\n",
       "      <td>6.831014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.019172</td>\n",
       "      <td>7.087069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.540000</td>\n",
       "      <td>9.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.180000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration    duration\n",
       "count  5131.000000  552.000000\n",
       "mean      6.805609    6.831014\n",
       "std       7.019172    7.087069\n",
       "min       0.300000    0.320000\n",
       "25%       1.640000    1.615000\n",
       "50%       4.100000    4.200000\n",
       "75%       9.540000    9.220000\n",
       "max      30.000000   29.180000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_csv['duration'].describe(), val_csv['duration'].describe()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>val_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fart</th>\n",
       "      <td>176</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flute</th>\n",
       "      <td>175</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Double_bass</th>\n",
       "      <td>172</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trumpet</th>\n",
       "      <td>170</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <td>169</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cello</th>\n",
       "      <td>168</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shatter</th>\n",
       "      <td>166</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applause</th>\n",
       "      <td>165</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bass_drum</th>\n",
       "      <td>163</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gong</th>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi-hat</th>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireworks</th>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saxophone</th>\n",
       "      <td>162</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarinet</th>\n",
       "      <td>159</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laughter</th>\n",
       "      <td>157</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snare_drum</th>\n",
       "      <td>156</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Squeak</th>\n",
       "      <td>154</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violin_or_fiddle</th>\n",
       "      <td>151</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cough</th>\n",
       "      <td>147</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oboe</th>\n",
       "      <td>146</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tearing</th>\n",
       "      <td>146</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Writing</th>\n",
       "      <td>145</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knock</th>\n",
       "      <td>138</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bark</th>\n",
       "      <td>133</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tambourine</th>\n",
       "      <td>122</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cowbell</th>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burping_or_eructation</th>\n",
       "      <td>102</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meow</th>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microwave_oven</th>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gunshot_or_gunfire</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmonica</th>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Keys_jangling</th>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electric_piano</th>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finger_snapping</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telephone</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chime</th>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bus</th>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glockenspiel</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scissors</th>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  val_label\n",
       "Fart                     176         19\n",
       "Flute                    175         19\n",
       "Double_bass              172         19\n",
       "Trumpet                  170         18\n",
       "Acoustic_guitar          169         18\n",
       "Cello                    168         18\n",
       "Shatter                  166         18\n",
       "Applause                 165         18\n",
       "Bass_drum                163         18\n",
       "Gong                     162         18\n",
       "Hi-hat                   162         18\n",
       "Fireworks                162         18\n",
       "Saxophone                162         17\n",
       "Clarinet                 159         17\n",
       "Laughter                 157         17\n",
       "Snare_drum               156         17\n",
       "Squeak                   154         17\n",
       "Violin_or_fiddle         151         16\n",
       "Cough                    147         16\n",
       "Oboe                     146         16\n",
       "Tearing                  146         16\n",
       "Writing                  145         16\n",
       "Knock                    138         15\n",
       "Bark                     133         14\n",
       "Tambourine               122         13\n",
       "Cowbell                  106         11\n",
       "Burping_or_eructation    102         11\n",
       "Meow                      90          9\n",
       "Drawer_open_or_close      85          9\n",
       "Microwave_oven            81          9\n",
       "Gunshot_or_gunfire        80          8\n",
       "Harmonica                 77          8\n",
       "Keys_jangling             75          8\n",
       "Electric_piano            73          8\n",
       "Finger_snapping           72          8\n",
       "Telephone                 72          8\n",
       "Chime                     71          7\n",
       "Computer_keyboard         60          6\n",
       "Bus                       58          6\n",
       "Glockenspiel              52          5\n",
       "Scissors                  51          5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_csv['label'].value_counts()).join(pd.DataFrame(val_csv['label'].value_counts()).rename({\"label\": \"val_label\"}, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 5128, 5129, 5130])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.sort_values(by=\"duration\")[0:300]\n",
    "train_csv.sort_values(by=\"duration\", ignore_index=True).index.values # [300*1:300*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_AST(huggingface_path):\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(huggingface_path)\n",
    "    model = ASTForAudioClassification.from_pretrained(huggingface_path)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # for param in model.audio_spectrogram_transformer.encoder.layer[-1].parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "    # for param in model.audio_spectrogram_transformer.encoder.layer[-1].output.dense.parameters():\n",
    "    #     param.requires_grad = True\n",
    "    # for param in model.audio_spectrogram_transformer.encoder.layer[-1].layernorm_before.parameters():\n",
    "    #     param.requires_grad = True\n",
    "    # for param in model.audio_spectrogram_transformer.encoder.layer[-1].layernorm_after.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "    model.audio_spectrogram_transformer.layernorm = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "    model.classifier.layernorm = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "    model.classifier.dense = nn.Linear(in_features=768, out_features=len(CLASSES_NAMES), bias=True)\n",
    "    \n",
    "    return feature_extractor, model\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, csv: pd.DataFrame, audio_dir: Path, sample_rate: int = 16000) -> None:\n",
    "        self.csv = csv.sort_values(by=\"duration\", ignore_index=True)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        self.audio_paths = {index: path for index, path in enumerate(self.csv['fname'])}\n",
    "        self.labels = {index: label for index, label in enumerate(self.csv['label'])}\n",
    "\n",
    "        self.label2id = {label: id_ for id_, label in enumerate(CLASSES_NAMES)}\n",
    "        self.id2label = {id_: label for id_, label in enumerate(CLASSES_NAMES)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.FloatTensor, torch.LongTensor]:\n",
    "        fname, label = self.audio_paths[index], self.labels[index]\n",
    "        audio, sr = sf.read(self.audio_dir / fname, dtype=\"float32\")\n",
    "        assert sr == self.sample_rate\n",
    "\n",
    "        target = torch.zeros(len(CLASSES_NAMES))\n",
    "        target[self.label2id[label]] = 1\n",
    "\n",
    "        return audio, target\n",
    "\n",
    "\n",
    "# import torch.utils.data as data\n",
    "\n",
    "\n",
    "# class DynamicalBatchSampler(data.Sampler):\n",
    "#     def __init__(self, dataset: Dataset, batch_size=None, shuffle=True, bucket_length=300):\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#         self.batch_size = batch_size\n",
    "#         self.shuffle = shuffle\n",
    "#         self.bucket_length = bucket_length\n",
    "\n",
    "#         self.buckets = list()\n",
    "        \n",
    "\n",
    "#     def __iter__(self):\n",
    "#         buckets = self.__get_buckets()\n",
    "\n",
    "#         batch_lists = []\n",
    "#         for j, cluster_indices in enumerate(self.data_source.cluster_indices):\n",
    "#             batches = [\n",
    "#                 cluster_indices[i : i + self.batch_sizes[j]]\n",
    "#                 for i in range(0, len(cluster_indices), self.batch_sizes[j])\n",
    "#             ]\n",
    "#             # filter our the shorter batches\n",
    "#             batches = [_ for _ in batches if len(_) == self.batch_sizes[j]]\n",
    "#             if self.shuffle:\n",
    "#                 random.shuffle(batches)\n",
    "#             batch_lists.append(batches)\n",
    "\n",
    "\n",
    "#         if self.shuffle:\n",
    "#             random.shuffle(lst)\n",
    "        \n",
    "#         return iter(lst)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data_source)\n",
    "    \n",
    "#     def __get_buckets(self):\n",
    "#         buckets: List[List[int]] = list()\n",
    "\n",
    "#         for factor in range((len(self.dataset.csv) // self.bucket_length) + 1):\n",
    "#             indexes = self.dataset.csv[self.bucket_length * factor : self.bucket_length * (factor + 1)].index.values\n",
    "#             buckets.append(indexes)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class CollateWrapper:\n",
    "    def __init__(self, feature_extractor) -> None:\n",
    "        self.sampling_rate = feature_extractor.sampling_rate\n",
    "        self.feature_extractor = feature_extractor\n",
    "        # self.feature_extractor.max_length = 2048\n",
    "\n",
    "    def __call__(self, batch: List[Tuple[torch.FloatTensor, torch.LongTensor]]):\n",
    "        audios, targets = list(zip(*batch))\n",
    "\n",
    "        # max_audio_len = max([audio.shape[-1] for audio in audios])\n",
    "        # max_melspectorgram_len = max_audio_len // 162\n",
    "        # max_melspectorgram_len = max_melspectorgram_len if max_melspectorgram_len < 2048 else 2048\n",
    "        # self.feature_extractor.max_length = max_melspectorgram_len\n",
    "        \n",
    "        \n",
    "        melspectorgrams = self.feature_extractor(audios, sampling_rate=self.sampling_rate, return_tensors=\"pt\").input_values\n",
    "        targets = torch.stack(targets, 0)\n",
    "        \n",
    "        return melspectorgrams, targets # .unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EPOCHS_NUMBER = 56\n",
    "EVAL_EPOCH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor, model = get_pretrained_AST(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset(train_csv, train_audio_path, sample_rate=16000)\n",
    "valset = Dataset(val_csv, train_audio_path, sample_rate=16000)\n",
    "collate_wrapper = CollateWrapper(feature_extractor)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, collate_fn=collate_wrapper, pin_memory=False, shuffle=False)\n",
    "valloader = DataLoader(valset, batch_size=BATCH_SIZE, collate_fn=collate_wrapper, pin_memory=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13120 / 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.22222222222223"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23360 / 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.93567251461988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55040 / 342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in trainloader:\n",
    "#     X, _ = batch\n",
    "#     print(X.shape)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.matshow(X[0].T, origin='lower')\n",
    "# for x in X:\n",
    "#     plt.matshow(x.T, origin='lower')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor(\n",
    "    compute_class_weight(\"balanced\", classes=CLASSES_NAMES, y=train_csv[\"label\"]).astype(np.float32)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(\n",
    "    reduction=\"mean\",\n",
    "    weight=weights.to(DEVICE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_accuracy = Accuracy(\n",
    "    task=\"multiclass\",\n",
    "    num_classes=len(CLASSES_NAMES),\n",
    "    multidim_average=\"global\",\n",
    "    average=\"macro\",\n",
    ")\n",
    "weighted_accuracy = Accuracy(\n",
    "    task=\"multiclass\",\n",
    "    num_classes=len(CLASSES_NAMES),\n",
    "    multidim_average=\"global\",\n",
    "    average=\"weighted\",\n",
    ")\n",
    "weighted_f1_score = F1Score(\n",
    "    task=\"multiclass\",\n",
    "    num_classes=len(CLASSES_NAMES),\n",
    "    multidim_average=\"global\",\n",
    "    average=\"weighted\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_PATH = Path(\"experiments/AST-exp1-sorted/\")\n",
    "submission_csv_path = EXPERIMENTS_PATH / \"submission.csv\"\n",
    "\n",
    "EXPERIMENTS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "(EXPERIMENTS_PATH / \"checkpoints\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111646/3357295872.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  trainloader_progress_bar = tqdm_notebook(trainloader, desc=description)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2b82a15a54430bc31535ee13a5d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 0/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.342644453048706 \n",
      "Accuracy: 0.652 \n",
      "Accuracy weighted: 0.648 \n",
      "F1 score weighted: 0.6515\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111646/3357295872.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  valloader_progress_bar = tqdm_notebook(valloader, desc=description)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcfa6e75d044926be7be9adf131c5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val data validation 0/56:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8206866979598999 \n",
      "Accuracy: 0.7577 \n",
      "Accuracy weighted: 0.7301 \n",
      "F1 score weighted: 0.7313\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a1e50a872247bbb19c1503521f9559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 1/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6005007028579712 \n",
      "Accuracy: 0.822 \n",
      "Accuracy weighted: 0.8164 \n",
      "F1 score weighted: 0.818\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee453d3b9694f28ac4f704d6cabbfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 2/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3868924677371979 \n",
      "Accuracy: 0.8848 \n",
      "Accuracy weighted: 0.8764 \n",
      "F1 score weighted: 0.8769\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce68b981659f4d89a9a7e74697fb0139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 3/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.27362900972366333 \n",
      "Accuracy: 0.9246 \n",
      "Accuracy weighted: 0.9174 \n",
      "F1 score weighted: 0.9174\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2cf3aa85454bf5a26dc93df9619f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val data validation 3/56:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6642104387283325 \n",
      "Accuracy: 0.8206 \n",
      "Accuracy weighted: 0.8207 \n",
      "F1 score weighted: 0.8229\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46364873fdba46d19649dc6e1580fb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 4/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20014140009880066 \n",
      "Accuracy: 0.9449 \n",
      "Accuracy weighted: 0.939 \n",
      "F1 score weighted: 0.939\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddc17c32727403184a3a29c5f8fbca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 5/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16203586757183075 \n",
      "Accuracy: 0.9558 \n",
      "Accuracy weighted: 0.9485 \n",
      "F1 score weighted: 0.9484\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd6dd0acc134aebb1a5e13a9eeaea62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 6/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12821343541145325 \n",
      "Accuracy: 0.9652 \n",
      "Accuracy weighted: 0.9591 \n",
      "F1 score weighted: 0.959\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeebfa34773468c96462ad9b1c9049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val data validation 6/56:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6887537837028503 \n",
      "Accuracy: 0.8385 \n",
      "Accuracy weighted: 0.837 \n",
      "F1 score weighted: 0.8407\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b87276f8db742569ef56ac38246877e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 7/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09773273020982742 \n",
      "Accuracy: 0.9721 \n",
      "Accuracy weighted: 0.968 \n",
      "F1 score weighted: 0.968\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5317915215433fbe7086c119fe8994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 8/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.07868345081806183 \n",
      "Accuracy: 0.9791 \n",
      "Accuracy weighted: 0.9747 \n",
      "F1 score weighted: 0.9746\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad691144ebdd4645a22c9bc63313668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 9/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05968992039561272 \n",
      "Accuracy: 0.9861 \n",
      "Accuracy weighted: 0.9834 \n",
      "F1 score weighted: 0.9835\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e795cb13534e3397c7102616385f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val data validation 9/56:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8024961948394775 \n",
      "Accuracy: 0.8333 \n",
      "Accuracy weighted: 0.8243 \n",
      "F1 score weighted: 0.8262\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69aed07439cd4ad6bba3bed31330f104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 10/56:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb Cell 22\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m description \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS_NUMBER\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m trainloader_progress_bar \u001b[39m=\u001b[39m tqdm_notebook(trainloader, desc\u001b[39m=\u001b[39mdescription)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_targets, train_predictions \u001b[39m=\u001b[39m train_epoch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     trainloader_progress_bar, model, criterion, optimizer, DEVICE\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss_value \u001b[39m=\u001b[39m criterion(train_predictions\u001b[39m.\u001b[39mto(DEVICE), train_targets\u001b[39m.\u001b[39mto(DEVICE))\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sazerlife/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/notebooks/train2.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_targets, train_predictions \u001b[39m=\u001b[39m train_targets\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint64), train_predictions\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/projects/courses/itmo/semester-2/event_detection/lab4-kaggle-audioset/train_val_functions.py:40\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m     model\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m     targets\u001b[39m.\u001b[39mappend(y\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m     41\u001b[0m     predictions\u001b[39m.\u001b[39mappend(output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m     42\u001b[0m     \u001b[39m# break\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[39m# Uniting of batches\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "\n",
    "for epoch in range(EPOCHS_NUMBER):\n",
    "    print(\"-\" * 80)\n",
    "    description = f\"Training {epoch}/{EPOCHS_NUMBER}\"\n",
    "    trainloader_progress_bar = tqdm_notebook(trainloader, desc=description)\n",
    "    train_targets, train_predictions = train_epoch(\n",
    "        trainloader_progress_bar, model, criterion, optimizer, DEVICE\n",
    "    )\n",
    "    \n",
    "    loss_value = criterion(train_predictions.to(DEVICE), train_targets.to(DEVICE)).item()\n",
    "    train_targets, train_predictions = train_targets.argmax(-1).to(torch.int64), train_predictions.argmax(-1)\n",
    "    train_log = (\n",
    "        f\"Loss: {loss_value} \\n\"\n",
    "        f\"Accuracy: {macro_accuracy(train_predictions, train_targets):.4} \\n\"\n",
    "        f\"Accuracy weighted: {weighted_accuracy(train_predictions, train_targets):.4} \\n\"\n",
    "        f\"F1 score weighted: {weighted_f1_score(train_predictions, train_targets):.4}\"\n",
    "    )\n",
    "    print(train_log)\n",
    "\n",
    "    if epoch % EVAL_EPOCH == 0:\n",
    "        print(\"-\" * 80)\n",
    "        description = f\"Val data validation {epoch}/{EPOCHS_NUMBER}\"\n",
    "        valloader_progress_bar = tqdm_notebook(valloader, desc=description)\n",
    "        val_targets, val_predictions = validate(valloader_progress_bar, model, DEVICE)\n",
    "\n",
    "        loss_value = criterion(val_predictions.to(DEVICE), val_targets.to(DEVICE)).item()\n",
    "        val_targets, val_predictions = val_targets.argmax(-1).to(torch.int64), val_predictions.argmax(-1)\n",
    "        val_log = (\n",
    "            f\"Loss: {loss_value} \\n\"\n",
    "            f\"Accuracy: {macro_accuracy(val_predictions, val_targets):.4} \\n\"\n",
    "            f\"Accuracy weighted: {weighted_accuracy(val_predictions, val_targets):.4} \\n\"\n",
    "            f\"F1 score weighted: {weighted_f1_score(val_predictions, val_targets):.4}\"\n",
    "        )\n",
    "        print(val_log)\n",
    "\n",
    "        torch.save(\n",
    "            model.state_dict(), EXPERIMENTS_PATH / \"checkpoints\" / f\"{epoch}.pt\",\n",
    "        )\n",
    "\n",
    "# The last save if we go out early then EVAL_EPOCH value\n",
    "torch.save(\n",
    "    model.state_dict(), EXPERIMENTS_PATH / \"checkpoints\" / f\"{epoch}.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EXPERIMENTS_PATH / \"checkpoints\" / f\"{30}.pt\")\n",
    "model.load_state_dict(torch.load(EXPERIMENTS_PATH / \"checkpoints\" / f\"{30}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(audio_path, feature_extractor, model):\n",
    "    waveform, sampling_rate = sf.read(audio_path)\n",
    "\n",
    "    inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    predicted_class_ids = torch.argmax(logits, dim=-1).cpu().item()\n",
    "    predicted_label = trainset.id2label[predicted_class_ids]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sampling_rate = sf.read(train_audio_path / val_csv[\"fname\"][1])\n",
    "\n",
    "inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits, dim=-1).cpu().item()\n",
    "predicted_label = trainset.id2label[predicted_class_ids]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = list()\n",
    "\n",
    "for fname in tqdm(val_csv['fname'].values):\n",
    "    predicted_label = inference(train_audio_path / fname, feature_extractor, model)\n",
    "    predicted_labels.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(val_csv[\"label\"].values, predicted_labels))\n",
    "print(f1_score(val_csv[\"label\"].values, predicted_labels, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(val_csv[\"label\"].values, predicted_labels))\n",
    "print(f1_score(val_csv[\"label\"].values, predicted_labels, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv[\"predicted_label\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, label, duration, predicted in val_csv[val_csv['label'] != val_csv['predicted_label']].sort_values(by=\"duration\").values:\n",
    "    print(f\"{label:20s} {duration:.4} {predicted:20s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(test_csv_path)\n",
    "\n",
    "predicted_labels = list()\n",
    "for fname in tqdm(test_csv['fname'].values):\n",
    "    predicted_label = inference(test_audio_path / fname, feature_extractor, model)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "test_csv['label'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.to_csv(EXPERIMENTS_PATH / \"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch=3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
